services:
  api-predict:
    build:
      context: .
      dockerfile: api/predict/Dockerfile
    image: api-predict
    container_name: api-predict
    depends_on:
      - tracking_server
      - s3
    ports:
      - "8002:8000"
    volumes:
      - ./api/predict:/app/predict # TODO remove for production
    environment:
      MLFLOW_TRACKING_URI: http://tracking_server:5000
    networks:
      - backend

  streamlit:
    build:
      context: streamlit
      dockerfile: Dockerfile
    image: streamlit
    container_name: streamlit
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit:/app # TODO remove for production
    environment:
      TMDB_API_TOKEN: ${TMDB_API_TOKEN}
      SUPABASE_URL: http://kong:8000
      SUPABASE_KEY: ${SUPABASE_KEY}
    networks:
      - backend

  db:
    restart: always
    image: postgres
    container_name: mlflow_db
    expose:
      - "${PG_PORT}"
    networks:
      - backend_mlflow
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
      - POSTGRES_DATABASE=${PG_DATABASE}
    volumes:
      - ./mlflow/db_data:/var/lib/postgresql/data/
    healthcheck:
      test: ["CMD", "pg_isready", "-p", "${PG_PORT}", "-U", "${PG_USER}"]
      interval: 5s
      timeout: 5s
      retries: 3

  s3:
    restart: always
    image: minio/minio
    container_name: mlflow_minio
    volumes:
      - ./mlflow/minio_data:/data
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    networks:
      - frontend
      - backend
      - backend_mlflow
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_ADDRESS=${MINIO_ADDRESS}
      - MINIO_PORT=${MINIO_PORT}
      - MINIO_STORAGE_USE_HTTPS=${MINIO_STORAGE_USE_HTTPS}
      - MINIO_CONSOLE_ADDRESS=${MINIO_CONSOLE_ADDRESS}
    command: server /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  tracking_server:
    restart: always
    build: ./mlflow
    image: mlflow_server
    container_name: mlflow_server
    depends_on:
      - db
    ports:
      - "${MLFLOW_PORT}:5000"
    networks:
      - frontend
      - backend_mlflow
      - backend
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${MINIO_PORT}
      - MLFLOW_S3_IGNORE_TLS=true
    command: >
      mlflow server
      --backend-store-uri postgresql://${PG_USER}:${PG_PASSWORD}@db:${PG_PORT}/${PG_DATABASE}
      --host 0.0.0.0
      --serve-artifacts
      --artifacts-destination s3://${MLFLOW_BUCKET_NAME}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MLFLOW_PORT}/"]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - shared_prometheus:/var/log/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - backend

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - shared_grafana:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - backend

volumes:
  db_data:
  minio_data:
  shared_prometheus:
  shared_grafana:

networks:
  frontend:
    driver: bridge
  backend_mlflow:
    driver: bridge
  backend:
    name: backend
    external: true
